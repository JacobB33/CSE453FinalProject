trainer_config:
  max_epochs: 10
  batch_size: 200
  data_loader_workers: 2
  grad_norm_clip: 1.0
  snapshot_path: final_model.pt
  save_every: 1
  use_amp: False
  use_wandb: True
  run_name: real_model_version_2
  use_lr_scheduler: True
lr_scheduler_config:
  type: plateau
  gamma: 0.5
  patience: 1
  mode: min
  threshold: 0.1
  min_lr: 0.0000001
  cooldown: 0
optimizer_config:
  optimizer: adam
  weight_decay: 0.0
  learning_rate: 0.00001
data_config:
  sequence_length: 120
model_config:
    vocab_size: 50281
    n_layers: 16
    embedding_size: 256
    nheads: 8
    max_seq_len: 120
    norm_eps: 0.0
    dropout: 0.0
    linear_dim: 256
compile: False
